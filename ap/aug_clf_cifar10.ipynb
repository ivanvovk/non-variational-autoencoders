{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from firelab.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Config.load('./CIFAR10_Z16_ae.yaml').to_dict()\n",
    "args['device'] = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = args['batch_size'],\n",
    "                                           shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = args['batch_size'] * 10,\n",
    "                                          shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Initializer(layers, slope=0.2):\n",
    "    for layer in layers:\n",
    "        if hasattr(layer, 'weight'):\n",
    "            w = layer.weight.data\n",
    "            std = 1/np.sqrt((1 + slope**2) * np.prod(w.shape[:-1]))\n",
    "            w.normal_(std=std)\n",
    "            \n",
    "        if hasattr(layer, 'bias'):\n",
    "            layer.bias.data.zero_()\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, scales, depth, latent, colors):\n",
    "        super().__init__()\n",
    "             \n",
    "        self.encoder = self._make_network(scales, depth, latent, colors, part='encoder')\n",
    "        self.decoder = self._make_network(scales, depth, latent, colors, part='decoder')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _make_network(scales, depth, latent, colors, part=None):\n",
    "        \"\"\"\n",
    "        input:\n",
    "        part - encoder/decoder, str\n",
    "        \"\"\"\n",
    "        activation = nn.LeakyReLU(0.01)   \n",
    "        \n",
    "        sub_network = []\n",
    "        \n",
    "        if part == 'encoder':\n",
    "            sub_network += [nn.Conv2d(colors, depth, 1, padding=1)]\n",
    "            \n",
    "            kp = depth\n",
    "            iterable = range(scales)\n",
    "            transformation = nn.AvgPool2d(2)\n",
    "            \n",
    "        elif part == 'decoder':\n",
    "            \n",
    "            kp = latent\n",
    "            iterable =range(scales - 1, -1, -1)\n",
    "            transformation = nn.Upsample(scale_factor=2)\n",
    "        \n",
    "        # joint part\n",
    "        for scale in range(scales):\n",
    "            k = depth << scale\n",
    "            sub_network.extend([nn.Conv2d(kp, k, 3, padding=1), activation,\n",
    "                                transformation])\n",
    "            kp = k\n",
    "        \n",
    "        if part == 'encoder':\n",
    "            k = depth << scales\n",
    "            sub_network.extend([nn.Conv2d(kp, k, 3, padding=1), activation, nn.Conv2d(k, latent, 3, padding=1)])\n",
    "        \n",
    "        elif part == 'decoder':\n",
    "            sub_network.extend([nn.Conv2d(kp, depth, 3, padding=1), activation, nn.Conv2d(depth, colors, 3, padding=1)])\n",
    "        \n",
    "        Initializer(sub_network)\n",
    "        return nn.Sequential(*sub_network)\n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, scales, depth, latent, colors):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.critic = Autoencoder._make_network(scales, depth, latent, colors, part='encoder')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.flatten(self.critic(x)).mean(dim=1)\n",
    "    \n",
    "    def descriptor(self, x):\n",
    "        return self.critic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_space_quality(autoencoder, dataloaders, device='cpu'):\n",
    "    cdn = lambda x: x.cpu().detach().numpy()\n",
    "    \n",
    "    train, test = dataloaders\n",
    "    autoencoder = autoencoder.to(device)\n",
    "    autoencoder.eval()\n",
    "    \n",
    "    def inference(model, loader):\n",
    "        descriptor=[]\n",
    "        for idx, (X, y) in enumerate(loader):\n",
    "            prediction, target = cdn(model.encoder(X.to(device))), cdn(y).reshape(-1,1)\n",
    "            descriptor.append(np.hstack([prediction.reshape(prediction.shape[0], -1), target]))\n",
    "        return np.vstack(descriptor)\n",
    "            \n",
    "    descriptor_train, descriptor_test = inference(autoencoder, train), inference(autoencoder, test)\n",
    "    \n",
    "    autoencoder.train()\n",
    "    \n",
    "    return (descriptor_train, descriptor_test)\n",
    "\n",
    "class DescriptorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, descriptor):\n",
    "        self.descriptor = descriptor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.descriptor)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        obj = torch.Tensor(self.descriptor[idx])\n",
    "        return (obj[:-1].float(), obj[-1])\n",
    "    \n",
    "    def fit_logistic_regression(self):\n",
    "        lr = LogisticRegressionCV(Cs=10, cv=5, max_iter=500)\n",
    "        lr.fit(descriptor[:, :-1], descriptor[:, -1])\n",
    "        \n",
    "        print(f'baseline acc: {[lr.scores_[k].mean() for k in lr.scores_.keys()]}')\n",
    "        \n",
    "    def fit_kmeans(self):\n",
    "        self.kmeans = KMeans(10)\n",
    "        self.kmeans.fit(self.descriptor[:, :-1])\n",
    "        \n",
    "        \n",
    "class SingleLayer(nn.Module):\n",
    "    def __init__(self, latent_dim, n_classes, dropout=0):\n",
    "        super().__init__()\n",
    "             \n",
    "        self.FC = nn.Linear(latent_dim, n_classes)\n",
    "        \n",
    "        if dropout!=0:\n",
    "            self.FC = nn.Sequential(nn.Dropout(dropout), self.FC)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.FC(x)\n",
    "    \n",
    "    \n",
    "def fit_FC(autoencoder, loaders, args):\n",
    "    \n",
    "    descr_train, descr_test = latent_space_quality(autoencoder, loaders, device=args['device'])    \n",
    "    train_descriptor_dataset, test_descriptor_dataset = DescriptorDataset(descr_train), DescriptorDataset(descr_test)\n",
    "    \n",
    "    train_descr_loader = torch.utils.data.DataLoader(train_descriptor_dataset, batch_size = 64, shuffle=True, drop_last=False)\n",
    "    test_descr_loader = torch.utils.data.DataLoader(test_descriptor_dataset, batch_size = 1000, shuffle=True, drop_last=False)\n",
    "    \n",
    "    criterion_CE = nn.CrossEntropyLoss()\n",
    "    test_accuracy = []    \n",
    "    \n",
    "    latent_dim = train_descriptor_dataset[0][0].shape[0]\n",
    "    \n",
    "    fc_layer = SingleLayer(latent_dim=latent_dim, n_classes=10, dropout=0).to(args['device'])\n",
    "    opt_fc = optim.Adam(fc_layer.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "#     scheduler = LambdaLR(opt_fc, lr_lambda=lambda epoch: 0.9 ** epoch)\n",
    "        \n",
    "    for epoch in range(20):\n",
    "        for index, (X, y) in tqdm(enumerate(train_descr_loader), total=len(train_descr_loader),\n",
    "                                  leave=False, desc=f'Fit FC, Epoch: {epoch}'):\n",
    "\n",
    "            y_hat = fc_layer(X.to(args['device']))\n",
    "            loss = criterion_CE(y_hat, y.to(args['device']).long())\n",
    "\n",
    "            opt_fc.zero_grad()\n",
    "            loss.backward()\n",
    "            opt_fc.step()\n",
    "\n",
    "        # Test Step\n",
    "        fc_layer.eval()\n",
    "\n",
    "        acc = 0\n",
    "        for index, (X, y) in enumerate(test_descr_loader):\n",
    "            y_hat = fc_layer(X.to(args['device'])).cpu().detach()\n",
    "            acc += (y == y_hat.argmax(dim=1)).sum().item()/y_hat.shape[0]\n",
    "        test_accuracy.append(acc/len(test_descr_loader))\n",
    "\n",
    "        fc_layer.train()\n",
    "        \n",
    "#         if epoch%2==0:\n",
    "#             scheduler.step()\n",
    "        \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(X):\n",
    "    aug_idx = np.random.randint(5)\n",
    "    if aug_idx == 0:\n",
    "        return torch.flip(X, (2,))\n",
    "    if aug_idx == 1:\n",
    "        return torch.flip(X, (3,))\n",
    "    if aug_idx == 2:\n",
    "        return torch.flip(X, (3, 2))\n",
    "    if aug_idx == 3:\n",
    "        return torch.flip(X, (1,))\n",
    "    if aug_idx == 4:\n",
    "        return torch.flip(X, (1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation experiments on AE with the classificator FC on the latent space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['device'] = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): LeakyReLU(negative_slope=0.01)\n",
       "    (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): LeakyReLU(negative_slope=0.01)\n",
       "    (12): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (9): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): LeakyReLU(negative_slope=0.01)\n",
       "    (11): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scales = int(round(math.log(args['width'] // args['latent_width'], 2)))\n",
    "autoencoder = Autoencoder(scales=scales, depth=args['depth'],\n",
    "                          latent=args['latent'], colors=args['colors']\n",
    "                         ).to('cuda:0')\n",
    "autoencoder.load_state_dict(torch.load('Autoencoder.torch', map_location='cuda:0'))\n",
    "autoencoder.to('cuda:0')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "autoencoder.decoder.eval()\n",
    "autoencoder.to('cuda:0')\n",
    "\n",
    "for X_origin, _ in train_loader:   \n",
    "    X_aug = augmentation(X_origin)\n",
    "    X_origin, X_aug = X_origin.to('cuda:0'), X_aug.to('cuda:0')\n",
    "    dist = []\n",
    "    for _ in range(6):\n",
    "        points_origin = autoencoder.encoder(X_origin)\n",
    "        points_aug = autoencoder.encoder(X_aug)\n",
    "\n",
    "        dist.append(((points_origin - points_aug) ** 2).sum().item() / 32)\n",
    "\n",
    "        out_origin, out_aug = autoencoder.decoder(points_origin), autoencoder.decoder(points_aug)\n",
    "\n",
    "        loss = F.mse_loss(X_origin, out_aug) + F.mse_loss(X_aug, out_origin)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    distances.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    }
   ],
   "source": [
    "results = fit_FC(autoencoder, (train_loader, test_loader), args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32374471544715444,\n",
       " 0.34065447154471545,\n",
       " 0.3519658536585365,\n",
       " 0.35992032520325207,\n",
       " 0.36841626016260165,\n",
       " 0.3730918699186992,\n",
       " 0.37949837398373987,\n",
       " 0.38428699186991866,\n",
       " 0.39053739837398377,\n",
       " 0.38910487804878047,\n",
       " 0.39213089430894305,\n",
       " 0.3969536585365853,\n",
       " 0.399950406504065,\n",
       " 0.39864878048780483,\n",
       " 0.40145691056910565,\n",
       " 0.40758373983739843,\n",
       " 0.4075666666666667,\n",
       " 0.40648130081300815,\n",
       " 0.41184552845528455,\n",
       " 0.4137276422764228]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
